{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619b4225-2020-4b5a-8c47-f246fcbd4c26",
   "metadata": {},
   "source": [
    "# LLM Inference  - Text Classification using Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0d7349-996c-43cd-b184-d709c238994d",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79627067-5654-4289-9867-46686726eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset,DatasetDict\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5fde05-8f30-4a26-bc8f-7f738ff80fae",
   "metadata": {},
   "source": [
    "## Instantiate a LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42832cb6-9608-4611-9e8c-ade5d9f9eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 22:56:32,630\tINFO worker.py:1749 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-29 22:56:36 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='meta-llama/Meta-Llama-3-70B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3-70B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=4, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-29 22:56:45 utils.py:608] Found nccl from library /home/u.ap164907/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=2577450)\u001b[0m INFO 04-29 22:56:45 utils.py:608] Found nccl from library /home/u.ap164907/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 04-29 22:56:49 selector.py:28] Using FlashAttention backend.\n",
      "\u001b[36m(RayWorkerWrapper pid=2577450)\u001b[0m INFO 04-29 22:56:49 selector.py:28] Using FlashAttention backend.\n",
      "\u001b[36m(RayWorkerWrapper pid=2577697)\u001b[0m INFO 04-29 22:56:45 utils.py:608] Found nccl from library /home/u.ap164907/.config/vllm/nccl/cu12/libnccl.so.2.18.1\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "INFO 04-29 22:56:50 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "\u001b[36m(RayWorkerWrapper pid=2577450)\u001b[0m INFO 04-29 22:56:50 pynccl_utils.py:43] vLLM is using nccl==2.18.1\n",
      "WARNING 04-29 22:56:56 custom_all_reduce.py:65] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerWrapper pid=2577450)\u001b[0m WARNING 04-29 22:56:56 custom_all_reduce.py:65] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[36m(RayWorkerWrapper pid=2577697)\u001b[0m INFO 04-29 22:56:49 selector.py:28] Using FlashAttention backend.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2577697)\u001b[0m INFO 04-29 22:56:50 pynccl_utils.py:43] vLLM is using nccl==2.18.1\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(RayWorkerWrapper pid=2577450)\u001b[0m INFO 04-29 22:57:16 weight_utils.py:193] Using model weights format ['*.safetensors']\n",
      "\u001b[36m(RayWorkerWrapper pid=2577697)\u001b[0m WARNING 04-29 22:56:56 custom_all_reduce.py:65] Custom allreduce is disabled because it's not supported on more than two PCIe-only GPUs. To silence this warning, specify disable_custom_all_reduce=True explicitly.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "INFO 04-29 22:57:16 weight_utils.py:193] Using model weights format ['*.safetensors']\n",
      "\u001b[36m(RayWorkerWrapper pid=2577450)\u001b[0m INFO 04-29 23:01:14 model_runner.py:173] Loading model weights took 32.8599 GBINFO 04-29 23:01:14 model_runner.py:173] Loading model weights took 32.8599 GB\n",
      "\n",
      "\u001b[36m(RayWorkerWrapper pid=2577594)\u001b[0m INFO 04-29 22:57:16 weight_utils.py:193] Using model weights format ['*.safetensors']\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "INFO 04-29 23:01:33 ray_gpu_executor.py:217] # GPU blocks: 3119, # CPU blocks: 3276\n",
      "INFO 04-29 23:01:43 block_manager_v1.py:235] Automatic prefix caching is enabled.\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "        model=\"meta-llama/Meta-Llama-3-70B-Instruct\",\n",
    "        tensor_parallel_size=4,\n",
    "        trust_remote_code=True,\n",
    "        enforce_eager=True,\n",
    "        gpu_memory_utilization=0.99,\n",
    "        enable_prefix_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28d56b0-ae04-49a4-b1fe-760f0c1a1e09",
   "metadata": {},
   "source": [
    "## Common function for all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89576d92-39f8-4d43-82cd-fcf2026982d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_classification(dataset_name, prefix):\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(dataset_name)\n",
    "\n",
    "    # Iterate over the dataset splits (train, test, validation)\n",
    "    modified_dataset_dict = {}\n",
    "    for split in [\"train\", \"test\", \"validation\"]:\n",
    "        # Get the texts and labels from the current split\n",
    "        texts = dataset[split][\"text\"]\n",
    "        labels = dataset[split][\"label\"]\n",
    "\n",
    "        # Generate the prompts for each Text\n",
    "        generating_prompts = [prefix + \"Text: \" + text + \"\\nResponse: \" for text in texts]\n",
    "\n",
    "        # Set the sampling parameters\n",
    "        sampling_params = SamplingParams(temperature=0, max_tokens=1)\n",
    "\n",
    "        # Generate the sentiment labels for each text\n",
    "        outputs = llm.generate(generating_prompts, sampling_params)\n",
    "        predicted_label = []\n",
    "        for output in outputs:\n",
    "            try:\n",
    "                predicted_label.append(int(output.outputs[0].text))\n",
    "            except ValueError:\n",
    "                predicted_label.append(-1)\n",
    "\n",
    "        # Add the predicted labels to the dataset\n",
    "        modified_dataset = dataset[split].add_column(\"predicted_label\", predicted_label)\n",
    "        modified_dataset_dict[split] = modified_dataset\n",
    "\n",
    "    # Create a DatasetDict with the modified datasets\n",
    "    return DatasetDict(modified_dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee03a7-b372-4f95-9a57-18b0dc93b79f",
   "metadata": {},
   "source": [
    "## Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2881b5-67f8-4a29-b401-d5cdbb18fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "You are an expert in sentiment analysis, with a deep understanding of natural language and human emotions.\n",
    "Your task is to analyze the sentiment of the given text and classify it as either positive or negative.\n",
    "When analyzing the sentiment, consider the overall tone, word choice, and emotional connotations within the text.\n",
    "Positive sentiment typically conveys happiness, joy, approval, or praise, while negative sentiment expresses sadness, anger, criticism, or disappointment.\n",
    "Provide your analysis in a concise and definitive manner, outputting either the number '1' if positive or '0' if negative based on your assessment of the sentiment expressed in the text.\n",
    "Do not provide any additional commentary or explanation beyond the sentiment classification itself.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9cad86-784c-4a22-8dda-464c82966916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 8700/8700 [02:22<00:00, 61.06it/s]\n",
      "Processed prompts: 100%|██████████| 1088/1088 [00:17<00:00, 63.13it/s]\n",
      "Processed prompts: 100%|██████████| 1088/1088 [00:17<00:00, 61.76it/s]\n"
     ]
    }
   ],
   "source": [
    "twitter_modified = zero_shot_classification(\n",
    "    dataset_name=\"MAdAiLab/twitter_disaster\",\n",
    "    prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abc59d2b-c9dc-4772-bff8-0133e9cb3f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'predicted_label'],\n",
       "        num_rows: 8700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'predicted_label'],\n",
       "        num_rows: 1088\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'predicted_label'],\n",
       "        num_rows: 1088\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b194a584-bd7b-4ee0-ae61-3daf446e96cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74aadb0bfc184537b3a7bdbcfb23a4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623ec286b28b4fb28a9e559ab185fd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd3b31f94a648f79fcc48adf1e1560f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1088 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "twitter_modified.save_to_disk(\"./output/twitter_predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d30faa-fc19-453f-a45b-57e95ce4f6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ba13a12-ac4a-4384-a280-39afcd0f79b6",
   "metadata": {},
   "source": [
    "## Patent Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ce00763-847d-4254-9762-4f637636c29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d481332fdf594b548f4cf300ae4a9445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/937 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f26b8ab593641faa9548199032372ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7af76028fc4c00858397e0ae6b290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.74M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be90aad7fcd4688a21822be3783782f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53722d5240a3493d805d5a58984037a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51723736a524e59a9008f5a431678b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a2ecdd802647358a35774ee8759b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patent_dataset = load_dataset(\"MAdAiLab/patent_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f24d4449-86fb-40de-bae4-4d2ad68fa8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 0, 7, 0, 8]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patent_dataset['train'][:5]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15d49db6-b877-49a0-ae01-4fe572cfa75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "You are an expert in patent classification, with a deep understanding of technical domains and patent categorization.\n",
    "Your task is to analyze the given patent abstract text and classify it into one of the 9 categories:\n",
    "'0': Human Necessities\n",
    "'1': Performing Operations; Transporting\n",
    "'2': Chemistry; Metallurgy\n",
    "'3': Textiles; Paper\n",
    "'4': Fixed Constructions\n",
    "'5': Mechanical Engineering; Lightning; Heating; Weapons; Blasting\n",
    "'6': Physics\n",
    "'7': Electricity\n",
    "'8': General tagging of new or cross-sectional technology\n",
    "When analyzing the patent, consider the technical field, invention type, and application area described in the text.\n",
    "Provide your classification in a concise and definitive manner, outputting the corresponding class label (0-8) based on your assessment of the patent's category.\n",
    "Do not provide any additional commentary or explanation beyond the classification itself.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b235b42-4429-44d8-bb8f-1d1017b7e691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 5/5 [00:00<00:00, 40.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Tweet: an apparatus for simultaneously testing multiple integrated circuits includes a sensing circuit associated with each of the tested circuits . each sensing circuit includes a differential amplifier with its positive input connected to the input of the test circuit , and its inversion input connected to the test circuit output . the test circuit input and positive amplifier input are biased to a selected voltage , and the voltage drop across the test circuit is provided to the amplifier inversion input . whenever the test circuit is open , intermittently open or highly resistive , the voltage drop across the test circuit exceeds the threshold voltage of the differential amplifier , causing the amplifier to generate a high level logic output representing an open circuit condition . the outputs of the various sensing circuits together form a digital word representative of the condition of all of the test circuits . the outputs of the differential amplifiers also are provided to independent triggering circuitry for enabling the storage of sensing circuit outputs upon an open condition indicated for at least one of the test circuits . the outputs of the sampling circuits are sampled in parallel at 100 nanosecond or longer selected intervals , so that extremely brief intermittent opens are detected .\n",
      "Response: 7\n",
      "Actual label: 6\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Tweet: an electrosurgical instrument includes a housing , a shaft extending from the housing , and an end effector assembly attached at a distal end of the shaft . a handle assembly is coupled to the housing and includes a movable handle for manipulating the end effector assembly . an outer sleeve is disposed about the shaft and selectively translatable relative thereto . an energizable member is operably coupled to the outer sleeve . a deployment mechanism is provided including a lever rotatably coupled to the housing and positioned proximally of the movable handle and at least one link member coupled between the lever and the outer sleeve . the link member couple to the outer sleeve distally of the movable handle . rotation of the lever translates the outer sleeve distally to move the outer sleeve over the end effector assembly and simultaneously deploy the energizable member distally past the end effector assembly .\n",
      "Response: 7\n",
      "Actual label: 0\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Tweet: a wireless transceiver device employing the code select code division multiple access method includes an encoder configured to execute error correction coding on data having a predetermined number of bits among data inputted from outside , and a code selector configured to select a code corresponding to the data subjected to correction coding . the wireless transceiver device performs wireless communication by use of the data inputted from the outside excluding the data having the predetermined number of bits and by use of the code .\n",
      "Response: 7\n",
      "Actual label: 7\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Tweet: the invention provides for the use of protein kinase activators or boosters of nerve growth factor , brain - derived neurotrophic factor or other neurotrophic factors to treat stroke . specifically , the present invention provides methods of treating stroke comprising the steps of identifying a subject having suffered a stroke and administering to said subject an amount of a pharmaceutical composition comprising a protein kinase c activator or 4 - methylcatechol acetic acid and a pharmaceutically acceptable carrier effective to treat at least one symptom of stroke .\n",
      "Response: 2\n",
      "Actual label: 0\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Tweet: the present invention relates to a device for mixing fluids . it is a hydraulic or pneumatic apparatus , depending on the fluid used for transportation . it is static and has the characteristics of both an extractor and a fluid mixer . extraction is effected by dragging the suction elements , by means of the circulation of a transporting fluid injected at low pressure . the injection inlets and suction inlets are interchangeable and lead to a single outlet . the injection tube formed by a helical spiral on the outside surrounded by the sheath increases the pressure in the transporting fluid and creates outward helical movement with centrifugal force in all the fluid that circulates on the outside .\n",
      "Response: 5\n",
      "Actual label: 8\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = patent_dataset['train'][:5]['text']\n",
    "labels = patent_dataset['train'][:5]['label']\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0, max_tokens=1)\n",
    "\n",
    "generating_prompts = [prefix + \"Text: \" + prompt + \"\\nResponse: \" for prompt in prompts]\n",
    "\n",
    "outputs = llm.generate(generating_prompts, sampling_params)\n",
    "\n",
    "# Print the outputs\n",
    "for i, output in enumerate(outputs, start=1):\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "\n",
    "    print(f\"Example {i}:\")\n",
    "    # print(f\"Prefix: {prefix.strip()}\")\n",
    "    print(f\"Text: {prompt.split('Text: ')[-1].strip()} {generated_text.strip()}\")\n",
    "    print(f\"Actual label: {labels[i-1]}\")\n",
    "    # print(f\"{generated_text.strip()}\")\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5548fdd-b862-4284-bc92-52e6567e31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 25000/25000 [23:26<00:00, 17.77it/s]\n",
      "Processed prompts: 100%|██████████| 5000/5000 [04:41<00:00, 17.75it/s]\n",
      "Processed prompts: 100%|██████████| 5000/5000 [04:42<00:00, 17.69it/s]\n"
     ]
    }
   ],
   "source": [
    "patent_modified = zero_shot_classification(\n",
    "    dataset_name=\"MAdAiLab/patent_classification\",\n",
    "    prefix=prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a842dde-949a-4e61-8cd6-070f78a903a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c960d2e1d5354c7286800d17f58c1199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5df2af2205744929189f40db3452f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff492394b12844d5b69ea710b5a2ffa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patent_modified.save_to_disk(\"./output/patent_predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f669d-abf5-43fc-a3f8-f0365ff2e4a2",
   "metadata": {},
   "source": [
    "## Scotus dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81564832-5b44-4733-a783-8937858f38af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770c3cbe26104f61a682aa26be5c6592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/813 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e0626fda4b47bb924e06f40faa919f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/94.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c22d3d5435343be83a5d754d068ae16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/40.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c102e8f3cff48c099087d6b7c06eb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/39.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833c88215f2c4bce910778efa631c1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd7e0c5ac3b4176980ebf173c8687a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27540c1f8d84a068bddf51159fa6655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scotus_dataset = load_dataset(\"MAdAiLab/lex_glue_scotus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84e2094f-851a-4744-82f2-77e0ab4f277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"\n",
    "You are an expert in legal issue area classification, with a deep understanding of the US Supreme Court's opinions and the subject matter of controversies.\n",
    "Your task is to analyze the given court opinion and classify it into one of the 14 relevant issue areas.\n",
    "When analyzing the opinion, consider the overall content, legal concepts, and subject matter within the text.\n",
    "The 14 issue areas are: (1) Criminal Procedure, (2) Civil Rights, (3) First Amendment, (4) Due Process, (5) Privacy, (6) Attorneys, (7) Unions, (8) Economic Activity, (9) Judicial Power, (10) Federalism, (11) Interstate Relations, (12) Federal Taxation, (13) Miscellaneous, and (14) Private Action.\n",
    "Provide your analysis in a concise and definitive manner, outputting the number corresponding to the relevant issue area based on your assessment of the opinion's content.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "293b2066-9345-4cac-8a43-cd7e45cb2cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  40%|████      | 2/5 [00:03<00:06,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-30 00:48:58 scheduler.py:619] Input prompt (11922 tokens) is too long and exceeds limit of 8192\n",
      "WARNING 04-30 00:48:58 scheduler.py:619] Input prompt (14879 tokens) is too long and exceeds limit of 8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 5/5 [00:06<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Actual label: 7\n",
      "Predicted label: 8\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "Actual label: 7\n",
      "Predicted label: 8\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "Actual label: 0\n",
      "Predicted label: 4\n",
      "--------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "Actual label: 1\n",
      "Predicted label: \n",
      "--------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "Actual label: 7\n",
      "Predicted label: \n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = scotus_dataset['train'][:5]['text']\n",
    "labels = scotus_dataset['train'][:5]['label']\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0, max_tokens=1)\n",
    "\n",
    "generating_prompts = [prefix + \"Text: \" + prompt + \"\\nResponse: \" for prompt in prompts]\n",
    "\n",
    "outputs = llm.generate(generating_prompts, sampling_params,)\n",
    "\n",
    "# Print the outputs\n",
    "for i, output in enumerate(outputs, start=1):\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "\n",
    "    print(f\"Example {i}:\")\n",
    "    # print(f\"Prefix: {prefix.strip()}\")\n",
    "    # print(f\"Text: {prompt.split('Text: ')[-1].strip()}\")\n",
    "    print(f\"Actual label: {labels[i-1]}\")\n",
    "    print(f\"Predicted label: {generated_text.strip()}\")\n",
    "    print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a757a7-7a35-4bfb-ba8d-b0a00013cbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
